{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "1 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "2 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "3 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "4 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "5 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "6 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "7 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "8 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "9 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "10 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "11 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "12 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "13 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "14 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "15 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "16 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "17 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "18 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "19 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "20 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "21 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "22 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "23 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "24 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "25 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "26 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "27 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "28 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "29 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "30 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "31 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "32 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "33 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "34 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "35 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "36 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "37 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "38 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "39 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "40 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "41 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "42 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "43 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "44 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "45 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "46 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "47 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "48 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "49 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "50 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "51 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "52 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "53 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "54 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "55 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "56 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "57 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "58 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "59 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "60 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "61 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "62 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "63 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "64 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "65 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "66 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "67 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "68 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "69 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "70 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "71 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "72 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "73 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "74 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "75 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "76 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "77 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "78 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "79 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "80 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "81 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "82 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "83 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "84 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "85 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "86 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "87 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "88 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "89 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "90 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "91 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "92 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "93 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "94 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "95 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "96 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "97 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "98 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "99 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "100 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "101 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "102 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "103 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "104 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "105 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "106 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "107 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "108 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "109 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "110 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "111 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "112 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "113 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "114 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "115 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "116 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "117 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "118 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "119 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "120 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "121 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "122 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "123 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "124 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "125 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "126 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "127 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "128 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "129 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "130 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "131 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "132 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "133 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "134 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "135 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "136 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "137 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "138 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "139 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "140 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "141 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "142 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "143 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "144 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "145 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "146 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "147 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "148 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "149 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "150 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "151 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "152 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "153 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "154 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "155 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "156 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "157 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "158 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "159 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "160 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "161 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "162 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "163 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "164 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "165 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "166 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "167 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "168 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "169 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "170 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "171 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "172 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "173 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "174 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "175 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "176 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "177 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "178 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "179 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "180 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "181 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "182 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "183 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "184 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "185 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "186 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "187 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "188 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "189 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "190 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "191 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "192 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "193 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "194 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "195 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "196 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "197 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "198 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "199 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "200 -2.8777475 [[ 0.6180538  -0.64044863 -0.30305913]\n",
      " [ 0.8063584   0.09972315  0.68362045]\n",
      " [-0.4138558  -0.9952862  -0.87643915]]\n",
      "Prediction: [0 0 0]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.constant(x_data, dtype=tf.float32)\n",
    "Y = tf.constant(y_data, dtype=tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random.normal([3, 3]))\n",
    "b = tf.Variable(tf.random.normal([3]))\n",
    "\n",
    "#hypothesis function\n",
    "def model(X, W, b):\n",
    "    return tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "#cross enthropy\n",
    "def loss(Y, hypothesis):\n",
    "    return tf.reduce_mean(tf.reduce_sum(Y * tf.math.log(hypothesis), axis=1))\n",
    "\n",
    "def train(X, Y, W, b, learning_rate=1e-10):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = model(X, W, b)\n",
    "        cost = loss(Y, hypothesis)\n",
    "        \n",
    "    gradients = tape.gradient(cost, [W, b])\n",
    "    \n",
    "    W.assign_sub(learning_rate * gradients[0])\n",
    "    b.assign_sub(learning_rate * gradients[1])\n",
    "\n",
    "def predict(X, W, b):\n",
    "    return tf.argmax(model(X, W, b), 1)\n",
    "\n",
    "def accuracy(X, Y, W, b):\n",
    "    prediction = predict(X, W, b)\n",
    "    is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "    return tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "for step in range(201):\n",
    "    train(X, Y, W, b)\n",
    "    cost_val = loss(Y, model(X, W, b))\n",
    "    print(step, cost_val.numpy(), W.numpy())\n",
    "\n",
    "x_test_var = tf.constant(x_test, dtype=tf.float32)\n",
    "print(\"Prediction:\", predict(x_test_var, W, b).numpy())\n",
    "print(\"Accuracy: \", accuracy(x_test_var, tf.constant(y_test, dtype=tf.float32), W, b).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'base'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "W = tf.Variable(tf.random.normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "def model(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "def loss(Y, hypothesis):\n",
    "    return tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=1e-5)\n",
    "\n",
    "def train(X, Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = model(X)\n",
    "        cost = loss(Y, hypothesis)\n",
    "    gradients = tape.gradient(cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "# Min-Max Normalization\n",
    "def min_max_normalize(dataset):\n",
    "    min_value = np.min(dataset, axis=0)\n",
    "    max_value = np.max(dataset, axis=0)\n",
    "    \n",
    "    return (dataset - min_value) / (max_value - min_value)\n",
    "\n",
    "x_data_normalized = min_max_normalize(x_data)\n",
    "y_data_normalized = min_max_normalize(y_data)\n",
    "\n",
    "X = tf.constant(x_data_normalized, dtype=tf.float32)\n",
    "Y = tf.constant(y_data_normalized, dtype=tf.float32)\n",
    "\n",
    "for step in range(101):\n",
    "    train(X, Y)\n",
    "    cost_val = loss(Y, model(X))\n",
    "    hy_val = model(X)\n",
    "    print(step, \"Cost: \", cost_val.numpy(), \"\\nPrediction:\\n\", hy_val.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m      5\u001b[0m mnist \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mmnist\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# 데이터셋을 로드하고 훈련 및 테스트 세트로 분할\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 정규화\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# 원-핫 인코딩\n",
    "y_train = tf.one_hot(y_train, depth=10)\n",
    "y_test = tf.one_hot(y_test, depth=10)\n",
    "\n",
    "# MNIST 이미지는 28x28 크기이므로 784 길이의 벡터로 변환\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "\n",
    "# 변수 설정 (Weight 초기화 방법 변경)\n",
    "W = tf.Variable(tf.random.uniform([784, 10], minval=-1., maxval=1.))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 가설 설정 (소프트맥스 사용)\n",
    "@tf.function\n",
    "def model(X):\n",
    "    return tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# 비용함수 (크로스 엔트로피 사용)\n",
    "def cost(X, Y):\n",
    "    return -tf.reduce_mean(tf.reduce_sum(Y * tf.math.log(model(X)), axis=1))\n",
    "\n",
    "# 경사 하강법 사용한 최적화\n",
    "def train(X, Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        c = cost(X, Y)\n",
    "        \n",
    "    gradients = tape.gradient(c, [W, b])\n",
    "    optimizer = tf.optimizers.SGD(learning_rate=0.1)\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "# 모델 테스트\n",
    "def is_correct(X, Y):\n",
    "    return tf.equal(tf.argmax(model(X), 1), tf.argmax(Y, 1))\n",
    "\n",
    "# 정확도 계산\n",
    "def accuracy(X, Y):\n",
    "    return tf.reduce_mean(tf.cast(is_correct(X, Y), tf.float32))\n",
    "\n",
    "# 매개변수\n",
    "num_epochs = 15\n",
    "batch_size = 100\n",
    "num_iterations = x_train.shape[0] // batch_size\n",
    "\n",
    "# 훈련 사이클\n",
    "for epoch in range(num_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        batch_xs, batch_ys = x_train[i * batch_size:(i+1) * batch_size], y_train[i * batch_size:(i+1) * batch_size]\n",
    "        train(batch_xs, batch_ys)\n",
    "        avg_cost += cost(batch_xs, batch_ys) / num_iterations\n",
    "\n",
    "    print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "print(\"Learning finished\")\n",
    "\n",
    "# 테스트 셋을 사용하여 모델 테스트 및 정확도 계산\n",
    "print(\"Accuracy: \", accuracy(x_test, y_test).numpy())\n",
    "\n",
    "# 하나의 예측값 가져오기\n",
    "r = random.randint(0, x_test.shape[0] - 1)\n",
    "print(\"Label: \", tf.argmax(y_test[r : r + 1], 1).numpy())\n",
    "print(\"Prediction: \", tf.argmax(model(x_test[r : r + 1]), 1).numpy())\n",
    "\n",
    "# 예측한 이미지 출력\n",
    "plt.imshow(x_test[r : r + 1].reshape(28, 28), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
